#+TITLE: Palindromic Products Benchmarking
#+AUTHOR: Peter Farr

* Overview
This project compares different implementations of the "palindromic products"
coding challenge, originally from Exercism (https://exercism.org).

** The problem
Given a range of integers [min, max] where min > 0, find:
- the smallest palindromic product of two factors in that range
- the largest palindromic product of two factors in that range

A palindromic product is a product whose decimal representation is a palindrome.

** Input constraints
All implementations require min > 0 (strictly positive inputs only). This constraint
eliminates edge cases with zero factors and allows for more predictable, optimized
code paths without special-case branching.

Additionally, for benchmarking and implementation comparability, we constrain
factor ranges to at most three-digit inputs (1..=999). This avoids extremely
long runtimes, recursion depth issues, and oversized temporary buffers that
can degrade cache behavior on some implementations.

Each function returns:
1. The palindrome value itself
2. The list of factor pairs that generate it

** The goal
We implement and benchmark solutions in Common Lisp (SBCL), Coalton, Rust, Go, and Haskell.
The objective is to measure performance trade-offs across languages and
algorithmic optimizations.

* Project layout
- =lisp/common-lisp/= Common Lisp implementation and build scripts
- =lisp/coalton-palindrome/= Coalton solution binaries and library
- =lisp/gc.lisp= Shared garbage collection utilities
- =rust-palindrome/= Rust solution binaries and library
- =go-palindrome/= Go solution binaries and library
- =haskell-palindrome/= Haskell solution binaries and library
- =palindrome-benchmark/= Criterion harness that drives all binaries
- =target-bin/= where all compiled executables are collected

* Benchmark Runner Design

The benchmark runners use a sophisticated iteration strategy to prevent compiler elision and ensure fair comparisons:

** Range-Based Iteration
Instead of running the same range repeatedly, the runners iterate across different ranges:
- =Smallest=: Varies =min= from =min= to =max= while keeping =max= constant
- =Largest=: Varies =max= from =max= to =min= while keeping =min= constant

** Accumulator Anti-Elision Trick
To ensure the compiler doesn't optimize away the work, each iteration:
1. Computes the palindrome result for the current range
2. Extracts the product and factor pairs from the result
3. Sums the factor pairs into a running accumulator
4. Adds the product, factor sum, and iteration counter to the accumulator
5. Returns both the final product and accumulator to prove work was done

This approach ensures that:
- Each iteration processes a different range (preventing memoization)
- The accumulator value changes on every iteration (preventing elision)
- The final accumulator value is returned and printed (proving work was done)

** Mathematical Distribution
For =N= total iterations across =R= ranges:
- Each range runs =N ÷ R= times (base iterations)
- The first =N mod R= ranges run one additional time (remainder iterations)
- Total iterations = =(N ÷ R) × R + (N mod R) = N= (exactly)

* Build all binaries (Lisp, Rust, Go, then Haskell)

** Common Lisp (SBCL)
From the =lisp/common-lisp/= directory, run the build script:

#+BEGIN_SRC shell
cd lisp/common-lisp
./build.sh
#+END_SRC

This produces executables in =target-bin/=:
- palprod-fast-smallest-inner
- palprod-fast-largest-inner

** Rust
From the =rust-palindrome/= directory, run the build script to produce both
release and PGO+BOLT-optimized binaries:

#+BEGIN_SRC shell
cd rust-palindrome
./build.sh
#+END_SRC

** Rust (PGO + BOLT via cargo-pgo)
We use `cargo-pgo` to generate PGO profiles and then optimize with BOLT on top of the PGO build. Install from `cargo install cargo-pgo`. You also need `llvm-profdata` and `llvm-bolt` (`cargo-pgo` docs: `https://github.com/Kobzol/cargo-pgo`).

Run the combined pipeline from =rust-palindrome/=:

#+BEGIN_SRC shell
cd rust-palindrome
# Optional: set workload size (defaults shown)
ITERS=15000000 WARMUP=250000 ./pgo_bolt_run.sh
#+END_SRC

This produces the following binaries in =target-bin/=: 
- palprod-rust-smallest-pgo-instrumented
- palprod-rust-smallest-bolt-optimized
- palprod-rust-largest-pgo-instrumented
- palprod-rust-largest-bolt-optimized

Notes:
- We do not keep a standalone PGO-optimized output; BOLT is always applied on top of the PGO build.
- Release symbols are preserved (no strip) for BOLT compatibility.

** Go
Build the Go solution and copy the binaries to =target-bin/=:

#+BEGIN_SRC shell
cd go-palindrome
./build.sh
#+END_SRC

** Go (PGO)
Go 1.21+ supports profile-guided optimization. We provide a script to collect a CPU profile using the same server workload as Rust and rebuild with PGO enabled.

#+BEGIN_SRC shell
cd go-palindrome
# Optional: override workload size (defaults shown)
ITERS=15000000 WARMUP=250000 ./build-pgo.sh
#+END_SRC

This produces the following additional binaries in =target-bin/=: 
- palprod-go-smallest-pgo
- palprod-go-largest-pgo

Notes:
- Our Criterion runs include these as “GO+PGO …” when present.
- On this specific workload and hardware, we observed strictly worse performance for GO+PGO compared to non-PGO builds. We still include them for completeness so readers can see the impact. Results may vary depending on profile representativeness and Go version. See the Go PGO docs for details: [Go PGO docs](https://go.dev/doc/pgo).

** Coalton
Build the Coalton solution and copy the binaries to =target-bin/=:

#+BEGIN_SRC shell
cd lisp/coalton-palindrome
./build.sh
#+END_SRC

** Haskell
Build the Haskell solution and copy the binaries to =target-bin/=:

#+BEGIN_SRC shell
cd haskell-palindrome
./build.sh
#+END_SRC

Important:
- The Haskell builds use the LLVM backend and rely on =-fllvm= being present in the
  =ghc-options= of =haskell-palindrome.cabal=. Cabal is the source of truth for
  flags; =build.sh= should not need to pass =--ghc-options= redundantly.
- With LLVM enabled, Haskell performance improved dramatically (4x vs the
  non-LLVM native backend in our tests).
- We also use primops in the palindrome predicate; however, the LLVM backend was
  the dominant factor in the speedup.

LLVM toolchain wiring (one-time):
- Ensure =llc-19= and =opt-19= are installed and visible in PATH.
- GHC 9.12.2 may report an empty "LLVM llvm-as command". We set GHC’s assembler
  driver to =clang= so GHC can pass assembler-style flags:
  - Edit =$(ghc --print-libdir)/settings= and set: ("LLVM llvm-as command","clang")
  - Verify via: =ghc --info | grep -i "llvm .*as"=
  - Confirm with verbose build: look for =opt-19=, =llc-19= and
    =LLVM assembler: clang= lines.

After these steps, =target-bin/= should contain the executables:
- palprod-fast-smallest-inner
- palprod-fast-largest-inner
- palprod-rust-smallest
- palprod-rust-largest
- palprod-rust-smallest-bolt-optimized
- palprod-rust-largest-bolt-optimized
- palprod-go-smallest
- palprod-go-largest
- palprod-coalton-smallest
- palprod-coalton-largest
- palprod-haskell-smallest
- palprod-haskell-largest

* Benchmark harness design

To ensure fair comparisons, we benchmark by shelling out to fully compiled
executables. This avoids bias from interpreter startup or compilation latency.

Criterion (in =palindrome-benchmark/=) runs each binary via a small harness that
acts like a "server": it performs warmups, then repeated timed runs. By
amortizing the process startup cost, the measurements reflect only the algorithm
runtime, not external overhead. This design makes cross-language benchmarking
much more reliable.

* Run tests

Each language implementation includes a test suite to verify correctness.

** Common Lisp
From the =lisp/common-lisp/= directory:

#+BEGIN_SRC shell
cd lisp/common-lisp
./run-tests.sh
#+END_SRC

** Coalton
From the =lisp/coalton-palindrome/= directory:

#+BEGIN_SRC shell
cd lisp/coalton-palindrome
./run-tests.sh
#+END_SRC

** Go
From the =go-palindrome/= directory:

#+BEGIN_SRC shell
cd go-palindrome
./run-tests.sh
#+END_SRC

** Haskell
From the =haskell-palindrome/= directory:

#+BEGIN_SRC shell
cd haskell-palindrome
./run-tests.sh
#+END_SRC

** Rust
From the =rust-palindrome/= directory:

#+BEGIN_SRC shell
cd rust-palindrome
cargo test
#+END_SRC

* Run the Criterion suite

The Criterion project expects all executables to already be present in =target-bin/=.

#+BEGIN_SRC shell
cd palindrome-benchmark
RUSTFLAGS="-C target-cpu=native" cargo bench
#+END_SRC

Criterion will run the configured scenarios and report timing distributions and
comparisons.

** Runner command protocol and strict input assumptions

All runners implement the same minimal line protocol and assume strictly correct input. This design removes parsing overhead (allocations, generic math, error branches) to ensure the benchmark measures only the palindrome algorithms.

- Protocol (one command per line):
  - =INIT <min> <max>=: set factor range (must be called before WARMUP/RUN)
  - =WARMUP <iters>=: run iterations without reporting product/accumulator
  - =RUN <iters>=: run iterations and print =OK <product> <acc>=
  - =QUIT=: exit

- Parsing assumptions shared by Common Lisp, Coalton, Rust, Go, and Haskell:
  - Commands are uppercase ASCII and start at column 0
  - Single ASCII space between tokens; no leading/trailing spaces
  - Unsigned decimal integers that fit in 32-bit for =min=, =max=, =iters=
  - Lines are terminated by a single newline (no carriage return required)
  - Unknown commands are ignored or treated as no-ops; no usage/help output
  - No defensive checks (e.g., input validation, =min<=max= checks) in runners

- Implementation notes:
  - First-character dispatch: =I=/=W=/=R=/=Q= selects the handler without token slicing
  - Fixed offsets to the first integer (e.g., after ="INIT "=) avoid extra scans
  - Integer parsing is zero-allocation and branch-light in all languages
  - Output is written directly to buffered stdout without formatting libraries

- Rationale: The benchmark harness (Criterion) fully controls inputs. By removing defensive parsing and dynamic dispatch, we avoid measurement skew from I/O and parsing overhead and keep the hot path consistently comparable across languages.

* Current results

Latest average times per iteration for largest:

| Implementation               |  Range | Task     | Time      |
|------------------------------+--------+----------+-----------|
| Haskell                      | 2..999 | largest  | 1.5632 µs |
| Rust                         | 2..999 | largest  | 1.5931 µs |
| Rust (PGO + Bolt)            | 2..999 | largest  | 1.6954 µs |
| Rust Functional              | 2..999 | largest  | 1.7442 µs |
| Rust Functional (PGO + Bolt) | 2..999 | largest  | 1.9054 µs |
| Rust Simd                    | 2..999 | largest  | 1.9208 µs |
| Rust Simd (PGO + Bolt)       | 2..999 | largest  | 1.9781 µs |
| Common Lisp                  | 2..999 | largest  | 2.1770 µs |
| Golang                       | 2..999 | largest  | 2.1909 µs |
| Golang (PGO)                 | 2..999 | largest  | 2.2508 µs |
| Coalton                      | 2..999 | largest  | 2.5647 µs |

Latest average times per iteration for smallest

| Implementation               |  Range | Task     | Time      |
|------------------------------+--------+----------+-----------|
| Rust Simd (PGO + Bolt)       | 2..999 | smallest | 1.6563 µs |
| Rust Simd                    | 2..999 | smallest | 1.7309 µs |
| Rust (PGO + Bolt)            | 2..999 | smallest | 1.8724 µs |
| Rust                         | 2..999 | smallest | 1.8840 µs |
| Haskell                      | 2..999 | smallest | 2.0211 µs |
| Rust Functional (PGO + Bolt) | 2..999 | smallest | 2.0344 µs |
| Rust Functional              | 2..999 | smallest | 2.2158 µs |
| Common Lisp                  | 2..999 | smallest | 3.0638 µs |
| Golang                       | 2..999 | smallest | 3.0794 µs |
| Golang (PGO)                 | 2..999 | smallest | 3.2461 µs |
| Coalton                      | 2..999 | smallest | 3.5845 µs |

* Rust functional implementation

I ported the Haskell-style, three-level recursive search to Rust. The first
version was slower than the imperative Rust solution. After switching to
Nightly and selectively adding the experimental `become` keyword to simple
tail-recursive helpers (palindrome half-reverse, factor-pair loop, and the
row-internal column scans), performance jumped drastically.

`become` is experimental, so it needed to be added incrementally, and needed to
avoid complex match-arm sites that triggered LLVM musttail errors or segfaults.

* Notes
- Haskell performance caveat: the Glasgow Haskell Compiler’s native backend was
  substantially slower for this workload. Enabling the LLVM backend (=-fllvm= via
  Cabal) yielded about a 4x speedup in our measurements and is required for the
  results listed above. Ensure your environment is correctly wiring LLVM tools
  (llc/opt and a working assembler driver) so the LLVM pipeline is actually used.
- All languages use a numeric half-reversal palindrome check (no strings).
- The Common Lisp code adds type declarations to encourage fixnum arithmetic in SBCL.
- We apply pruning (outer and inner) and early exits (for example divisibility by 11 on even-digit products) to reduce calls to the palindrome predicate.

* Coalton performance caveats and learnings

Coalton is great for clarity, but there are important performance caveats for hot paths:

+ Zero?/nonzero? class dispatch:
  Using =zero?= and =nonzero?= is elegant, but these are class-based and can add pointer dispatch overhead. In tight loops prefer direct comparisons (=== 0=, =/= 0=) on concrete unboxed numeric types.
+ No multiple values in Coalton:
  Coalton cannot directly consume Common Lisp multiple values, so idioms like =(multiple-value-bind (q r) (truncate ...))= don’t map cleanly. Wrapping into a =Tuple= allocates and adds pointer indirection; CPS via =coalton:call-coalton-function= adds per-iteration call indirection. In hot loops, prefer computing the quotient once and deriving the remainder (e.g., =q = n / 10= then =r = n - q*10=), which SBCL strength-reduces to a single magic-multiply sequence.
+ Option/Result are not zero-cost:
  Unlike Rust, Coalton’s =Optional= and =Result= involve heap allocation/boxing at boundaries. Keep them out of inner loops; construct results at the edges of computations.
+ Fusing div/mod work:
  There’s no zero-cost way in Coalton to return both quotient and remainder without extra allocation or calls. For non-constant divisors (e.g., factor checks), fuse the operations via one CL =truncate= and branch on the remainder, reusing the quotient. Our helper =nonzero-quot-if-divisible= encodes this and compiles to a single =idiv= plus a remainder test.
+ Recursion and inlining limits:
  Coalton’s pure style encourages recursion, but the compiler may refuse to inline recursive functions (stack frame size, heuristics), introducing call overhead. Prefer simple loops encoded as tail recursion that the compiler can flatten, or move arithmetic into small =inline= CL-backed helpers.
+ Allocation awareness:
  Returning =Tuple= or building temporary collections inside hot loops causes per-iteration allocation and GC pressure. Use unboxed arithmetic, avoid tuples in inner loops, and preallocate scratch storage (e.g., a small =LispArray U32=) if needed.
+ Bridge boundaries:
  Crossing Coalton↔CL via =lisp= forms is fast for arithmetic when returning unboxed scalars, but calling Coalton lambdas back from CL requires =coalton:call-coalton-function= (function-entry application) and is costly per-iteration. Avoid CPS patterns in hot loops.

Practical patterns we adopted:

- Palindrome half-reverse: compute =q= once, derive =r= via =r = n - q*10=.
- Factor pairs: use a helper that returns the quotient-or-zero from a single =truncate= and branch once.
- Keep Optional construction at function boundaries, not in inner loops.

Verification utilities:
- =test_correctness.sh= cross-checks all server binaries (range 1..999) and
  asserts identical product/accumulator outputs across languages.

* Attribution
Problem statement: Exercism, Common Lisp track, Palindrome Products
https://exercism.org/tracks/common-lisp/exercises/palindrome-products

This repository extends the original exercise with performance-focused
implementations and cross-language benchmarks.
